{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM 4040 - Assignment 1, Task 3: Dimensionality Reduction\n",
    "\n",
    "Here is the third part and it is about dimentionality reduction. How to map high-dimentional data into low-dimensional space is an interesting topic in machine learning field. And also, it is related to another hot topic -- unsupervised learning. Now, in this section, you are going to learn two different methods for this question.\n",
    "\n",
    "* Principal Component Analysis (PCA)\n",
    "* t-Distributed Stochastic Neighbor Embedding (t-SNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from ecbm4040.cifar_utils import load_data\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We will use the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "X_train = X_train.reshape([50000,3,32,32]).transpose((0,2,3,1))\n",
    "X_test = X_test.reshape([10000,3,32,32]).transpose((0,2,3,1))\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 49000 samples from original train set: 1~49000\n",
    "# Validation data: 1000 samples from original train set: 49000~50000\n",
    "# Test data: 10000 samples from original test set: 1~10000\n",
    "# Development data (for gradient check): 100 from the train set: 1~49000 #TODOTA is this 100 or 1000?\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_dev = 100\n",
    "\n",
    "X_val = X_train[-num_validation:]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "X_train = X_train[:num_training]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "# Preprocessing: subtract the mean value across every dimension for training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "X_test = X_test.astype(np.float32) - mean_image\n",
    "X_dev = X_dev.astype(np.float32) - mean_image\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('Development data shape:', X_dev.shape)\n",
    "print('Development data shape', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Principal Component Analysis (PCA)\n",
    "\n",
    "<span style=\"color:red\"><strong>TODO</strong></span>: You have to complete the code in **./ecbm4040/features/pca.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ecbm4040.features.pca import pca_naive\n",
    "\n",
    "X_patch = X_train[:,:,:,0]\n",
    "X_patch = np.reshape(X_patch, (X_patch.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start PCA\n",
    "K = 200\n",
    "P, T = pca_naive(X_patch, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Show principle components of P using a 4x4 subplot\n",
    "# Visualize P\n",
    "r = 4\n",
    "f, axarr = plt.subplots(r, r, figsize=(8,8))\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        img = np.reshape(P[r*i+j], [32,32])\n",
    "        axarr[i][j].imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a small set of images for test\n",
    "num_training = 50000\n",
    "num_pca = 16\n",
    "mask = np.random.choice(num_training, num_pca, replace=False)\n",
    "X_pca = X_train[mask,:,:,0]\n",
    "\n",
    "# Visualize one channel of images \n",
    "r = 4\n",
    "f, axarr = plt.subplots(r, r, figsize=(8,8))\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        img = X_pca[r*i+j]\n",
    "        axarr[i][j].imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Test your result\n",
    "# Reduce dimension with P\n",
    "X_features = []\n",
    "for n in range(num_pca):\n",
    "    img = X_pca[n]\n",
    "    feature = np.dot(P, np.reshape(img, (-1,)))\n",
    "    X_features.append(feature)\n",
    "\n",
    "# Reconstruct image\n",
    "X_recon = []\n",
    "for n in range(num_pca):\n",
    "    feature = X_features[n]\n",
    "    img = np.reshape(np.dot(feature, P), (32,32))\n",
    "    X_recon.append(img)\n",
    "\n",
    "# Visualize results\n",
    "r = 4\n",
    "f, axarr = plt.subplots(r, r, figsize=(8,8))\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        img = X_recon[r*i+j]\n",
    "        axarr[i][j].imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + Neural network\n",
    "\n",
    "<span style=\"color:red\"><strong>TODO</strong></span>: Use PCA to preprocess images before training a neural network: \n",
    "\n",
    "1. Do PCA preprocessing on each channel of the original image separately.\n",
    "2. Stack PCA features from three channels into one vector, and use that vector as an input for MLP.\n",
    "3. Train the MLP and show the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ecbm4040.train_funcs import train, test\n",
    "from ecbm4040.classifiers.mlp import MLP\n",
    "\n",
    "# TODO: pca preprocessing -> mlp classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><strong>TODO</strong></span>: Plot training, validation and test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: t-SNE (not graded)\n",
    "\n",
    "t-SNE is is a machine learning algorithm for nonlinear dimensionality reduction developed by Geoffrey Hinton and Laurens van der Maaten. It is also a good way of visualizing high-dimensional data in 2D. We show its application for CIFAR10. Later it will be re-used in a CNN network. Experimenting with t-SNE can be fun. One thing to try is to visualize the output of each layer of MLP to observe the differences.\n",
    "\n",
    "<p style=\"line-height: 1.2;\">[1] Maaten, Laurens van der, and Geoffrey Hinton. \"Visualizing data using t-SNE.\" Journal of Machine Learning Research 9.Nov (2008): 2579-2605.</p>\n",
    "<p style=\"line-height: 1.2;\">[2] Adaptive learning rate scheme by Jacobs https://www.willamette.edu/~gorr/classes/cs449/Momentum/deltabardelta.html</p>\n",
    "<p style=\"line-height: 1.2;\">[3] http://cs.stanford.edu/people/karpathy/cnnembed/</p>\n",
    "<p style=\"line-height: 1.2;\">[4] How to Use t-SNE Effectively, with examples.\n",
    " https://distill.pub/2016/misread-tsne</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ecbm4040.features.tsne import tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_select = np.random.choice(10000, 500, replace=False)\n",
    "X = X_test[random_select,:,:,0].reshape(500,1024).astype('float')/255.0\n",
    "tic = time.time()\n",
    "Y = tsne(X, low_dim=2, perplexity=30.0)\n",
    "print(\"it takes {} seconds\".format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## visualize tSNE of original data\n",
    "labels = y_test[random_select]\n",
    "colors = np.random.rand(10,3)\n",
    "color_labels = [colors[int(i)] for i in labels.tolist()]\n",
    "plt.scatter(Y[:,0], Y[:,1], 20, color_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE of data after two hidden layers\n",
    "\n",
    "In the visualization result, you should find that in comparison with the tSNE of original data where all data points mess up with each other, the tSNE of data after two-layer networks is shown as multiple clusters in a 2D panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define MLP model\n",
    "model = MLP(input_dim=3072, hidden_dims=[100], num_classes=10, reg=0.1, weight_scale=1e-2)\n",
    "\n",
    "num_epoch = 10\n",
    "batch_size = 200\n",
    "lr = 1e-3\n",
    "verbose = False\n",
    "train_acc_hist, val_acc_hist = train(model, X_train, y_train, X_val, y_val, \n",
    "                  num_epoch=num_epoch, batch_size=batch_size, learning_rate=lr, verbose=verbose)\n",
    "test(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run tSNE\n",
    "X = X_test[random_select]\n",
    "X = model.layers[0].feedforward(X)\n",
    "X = model.layers[1].feedforward(X)\n",
    "X_exp = np.exp(X)\n",
    "X = X_exp / np.tile(np.sum(X_exp, axis=1, keepdims=True), 10)\n",
    "\n",
    "tic = time.time()\n",
    "Y = tsne(X, low_dim=2, perplexity=30.0)\n",
    "print(\"it takes {} seconds\".format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize tSNE 2D representation of data after two hidden layers\n",
    "labels = y_test[random_select]\n",
    "colors = np.random.rand(10,3)\n",
    "color_labels = [colors[int(i)] for i in labels.tolist()]\n",
    "plt.scatter(Y[:,0], Y[:,1], 20, color_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
